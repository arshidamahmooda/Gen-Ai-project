# -*- coding: utf-8 -*-
"""gen ai project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oDHlN_KctW9NttVcGD936UcDIM56jJ4t
"""

!pip install tensorflow matplotlib scikit-learn pillow --quiet

import zipfile
import os

zip_path = '/content/archive (2).zip'
extract_dir = '/content/dataset'

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print("âœ… Dataset extracted to:", extract_dir)

import os

for root, dirs, files in os.walk("/content/dataset"):
    print(root, "->", len(files), "files")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_dir = '/content/dataset/Worksite-Safety-Monitoring-Dataset/train'
val_dir   = '/content/dataset/Worksite-Safety-Monitoring-Dataset/valid'

train_gen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

val_gen = ImageDataGenerator(rescale=1./255)

train_data = train_gen.flow_from_directory(
    train_dir, target_size=(128,128), batch_size=8, class_mode='binary'
)

val_data = val_gen.flow_from_directory(
    val_dir, target_size=(128,128), batch_size=8, class_mode='binary'
)

from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
import tensorflow as tf

base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(128,128,3))
base.trainable = False

model = Sequential([
    base,
    GlobalAveragePooling2D(),
    Dropout(0.4),
    Dense(64, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

history = model.fit(train_data, validation_data=val_data, epochs=8)

base.trainable = True
for layer in base.layers[:-50]:
    layer.trainable = False

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
              loss='binary_crossentropy',
              metrics=['accuracy'])

history_fine = model.fit(train_data, validation_data=val_data, epochs=5)

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

val_data.reset()
preds = (model.predict(val_data) > 0.5).astype("int32").flatten()
print(classification_report(val_data.classes, preds, target_names=['Safe', 'Unsafe']))
print("Confusion Matrix:\n", confusion_matrix(val_data.classes, preds))

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'] + history_fine.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'] + history_fine.history['val_accuracy'], label='Val')
plt.title('Model Accuracy')
plt.legend()
plt.show()

model.save('/content/efficientnet_hazard_model.h5')
print("âœ… Model saved!")

from PIL import Image, ImageEnhance
import glob

source_folder = "/content/dataset/Worksite-Safety-Monitoring-Dataset/train/unsafe"
target_folder = "/content/dataset/Worksite-Safety-Monitoring-Dataset/train/unsafe_synthetic"
os.makedirs(target_folder, exist_ok=True)

for img_path in glob.glob(f"{source_folder}/*.jpg")[:10]:
    img = Image.open(img_path)
    img = ImageEnhance.Brightness(img).enhance(1.3)
    img = ImageEnhance.Contrast(img).enhance(1.4)
    name = os.path.basename(img_path).replace("/content/79.jpg", "_gen.jpg")
    img.save(f"{target_folder}/{name}")

print("ðŸ§  Synthetic hazard images created!")

